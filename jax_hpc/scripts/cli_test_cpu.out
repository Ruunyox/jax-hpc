Module for Anaconda 2023.09 (Python 3.9.18) loaded.
Creating model...
Done...
Creating trainer...
Done...
Initializing datasets...
2023-11-24 03:28:06.813287: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
Initializing...
Done...
Epoch 0: [train 6.2512] --> [val 0.8542] --> [val acc 0.8078]
Epoch 1: [train 0.7669] --> [val 0.5498] --> [val acc 0.8443]
Epoch 2: [train 0.5675] --> [val 0.4546] --> [val acc 0.8591]
Epoch 3: [train 0.4583] --> [val 0.4279] --> [val acc 0.8640]
Epoch 4: [train 0.3987] --> [val 0.3903] --> [val acc 0.8705]
Epoch 5: [train 0.3635] --> [val 0.3376] --> [val acc 0.8835]
Epoch 6: [train 0.3455] --> [val 0.3151] --> [val acc 0.8898]
Epoch 7: [train 0.3363] --> [val 0.3168] --> [val acc 0.8906]
Epoch 8: [train 0.3065] --> [val 0.2927] --> [val acc 0.8968]
Epoch 9: [train 0.2890] --> [val 0.2676] --> [val acc 0.9035]
Epoch 10: [train 0.2625] --> [val 0.2669] --> [val acc 0.9040]
Epoch 11: [train 0.2461] --> [val 0.2528] --> [val acc 0.9082]
Epoch 12: [train 0.2321] --> [val 0.2493] --> [val acc 0.9093]
Epoch 13: [train 0.2268] --> [val 0.2344] --> [val acc 0.9152]
Epoch 14: [train 0.2148] --> [val 0.2399] --> [val acc 0.9134]
Epoch 15: [train 0.2067] --> [val 0.2341] --> [val acc 0.9171]
Epoch 16: [train 0.2052] --> [val 0.2293] --> [val acc 0.9178]
Epoch 17: [train 0.2027] --> [val 0.2476] --> [val acc 0.9138]
Epoch 18: [train 0.2001] --> [val 0.2278] --> [val acc 0.9187]
Epoch 19: [train 0.2016] --> [val 0.2300] --> [val acc 0.9193]
Epoch 20: [train 0.2044] --> [val 0.2180] --> [val acc 0.9231]
Epoch 21: [train 0.1952] --> [val 0.2555] --> [val acc 0.9108]
Epoch 22: [train 0.1869] --> [val 0.2400] --> [val acc 0.9159]
Epoch 23: [train 0.1786] --> [val 0.2178] --> [val acc 0.9219]
Epoch 24: [train 0.1895] --> [val 0.2025] --> [val acc 0.9250]
Epoch 25: [train 0.1959] --> [val 0.2140] --> [val acc 0.9229]
Epoch 26: [train 0.1799] --> [val 0.2247] --> [val acc 0.9215]
Epoch 27: [train 0.1814] --> [val 0.2315] --> [val acc 0.9189]
Epoch 28: [train 0.1807] --> [val 0.2434] --> [val acc 0.9184]
Epoch 29: [train 0.1895] --> [val 0.2378] --> [val acc 0.9207]
Epoch 30: [train 0.1771] --> [val 0.2716] --> [val acc 0.9111]
Epoch 31: [train 0.1746] --> [val 0.2078] --> [val acc 0.9258]
Epoch 32: [train 0.1868] --> [val 0.2066] --> [val acc 0.9261]
Epoch 33: [train 0.1779] --> [val 0.2820] --> [val acc 0.9122]
Epoch 34: [train 0.1909] --> [val 0.2158] --> [val acc 0.9231]
Epoch 35: [train 0.1810] --> [val 0.1949] --> [val acc 0.9302]
Epoch 36: [train 0.1816] --> [val 0.2135] --> [val acc 0.9250]
Epoch 37: [train 0.1657] --> [val 0.2023] --> [val acc 0.9289]
Epoch 38: [train 0.1773] --> [val 0.2128] --> [val acc 0.9251]
Epoch 39: [train 0.1709] --> [val 0.2064] --> [val acc 0.9274]
Epoch 40: [train 0.1842] --> [val 0.1894] --> [val acc 0.9319]
Epoch 41: [train 0.1795] --> [val 0.2164] --> [val acc 0.9247]
Epoch 42: [train 0.1814] --> [val 0.1946] --> [val acc 0.9294]
Epoch 43: [train 0.1755] --> [val 0.1958] --> [val acc 0.9323]
Epoch 44: [train 0.1733] --> [val 0.1825] --> [val acc 0.9338]
Epoch 45: [train 0.1614] --> [val 0.1937] --> [val acc 0.9315]
Epoch 46: [train 0.1654] --> [val 0.1814] --> [val acc 0.9369]
Epoch 47: [train 0.1722] --> [val 0.2060] --> [val acc 0.9282]
Epoch 48: [train 0.1669] --> [val 0.1872] --> [val acc 0.9353]
Epoch 49: [train 0.1673] --> [val 0.2448] --> [val acc 0.9200]
Epoch 50: [train 0.1745] --> [val 0.2202] --> [val acc 0.9221]
Epoch 51: [train 0.1756] --> [val 0.2608] --> [val acc 0.9175]
Epoch 52: [train 0.1652] --> [val 0.2263] --> [val acc 0.9201]
Epoch 53: [train 0.1663] --> [val 0.2119] --> [val acc 0.9238]
Epoch 54: [train 0.1588] --> [val 0.1914] --> [val acc 0.9316]
Epoch 55: [train 0.1541] --> [val 0.1940] --> [val acc 0.9317]
Epoch 56: [train 0.1663] --> [val 0.2248] --> [val acc 0.9260]
Epoch 57: [train 0.1741] --> [val 0.1845] --> [val acc 0.9338]
Epoch 58: [train 0.1513] --> [val 0.1794] --> [val acc 0.9347]
Epoch 59: [train 0.1595] --> [val 0.1728] --> [val acc 0.9371]
Epoch 60: [train 0.1435] --> [val 0.1709] --> [val acc 0.9377]
Epoch 61: [train 0.1479] --> [val 0.1936] --> [val acc 0.9293]
Epoch 62: [train 0.1486] --> [val 0.1919] --> [val acc 0.9303]
Epoch 63: [train 0.1539] --> [val 0.1935] --> [val acc 0.9307]
Epoch 64: [train 0.1510] --> [val 0.1661] --> [val acc 0.9393]
Epoch 65: [train 0.1594] --> [val 0.1989] --> [val acc 0.9305]
Epoch 66: [train 0.1526] --> [val 0.1707] --> [val acc 0.9373]
Epoch 67: [train 0.1481] --> [val 0.2063] --> [val acc 0.9278]
Epoch 68: [train 0.1498] --> [val 0.1728] --> [val acc 0.9364]
Epoch 69: [train 0.1439] --> [val 0.1642] --> [val acc 0.9395]
Epoch 70: [train 0.1391] --> [val 0.1898] --> [val acc 0.9350]
Epoch 71: [train 0.1409] --> [val 0.1964] --> [val acc 0.9314]
Epoch 72: [train 0.1403] --> [val 0.1615] --> [val acc 0.9407]
Epoch 73: [train 0.1427] --> [val 0.1710] --> [val acc 0.9390]
Epoch 74: [train 0.1351] --> [val 0.1721] --> [val acc 0.9397]
Epoch 75: [train 0.1329] --> [val 0.1963] --> [val acc 0.9327]
Epoch 76: [train 0.1386] --> [val 0.1772] --> [val acc 0.9390]
Epoch 77: [train 0.1374] --> [val 0.1719] --> [val acc 0.9386]
Epoch 78: [train 0.1391] --> [val 0.1882] --> [val acc 0.9346]
Epoch 79: [train 0.1343] --> [val 0.1657] --> [val acc 0.9431]
Epoch 80: [train 0.1252] --> [val 0.1788] --> [val acc 0.9370]
Epoch 81: [train 0.1289] --> [val 0.1696] --> [val acc 0.9400]
Epoch 82: [train 0.1228] --> [val 0.1809] --> [val acc 0.9386]
Epoch 83: [train 0.1289] --> [val 0.1756] --> [val acc 0.9387]
Epoch 84: [train 0.1195] --> [val 0.1886] --> [val acc 0.9387]
Epoch 85: [train 0.1120] --> [val 0.1813] --> [val acc 0.9387]
Epoch 86: [train 0.1064] --> [val 0.1825] --> [val acc 0.9386]
Epoch 87: [train 0.1247] --> [val 0.1898] --> [val acc 0.9376]
Epoch 88: [train 0.1298] --> [val 0.1603] --> [val acc 0.9445]
slurmstepd: error: *** JOB 7504652 ON bcn1001 CANCELLED AT 2023-11-24T03:36:38 ***
============ Job Information ===================================================
Submitted: 2023-11-24T03:27:55
Started: 2023-11-24T03:27:55
Ended: 2023-11-24T03:36:38
Elapsed: 9 min, Limit: 30 min, Difference: 21 min
(HT-)CPUs: 192, Nodes: 1
Estimated core-h: 13.9418
================================================================================
